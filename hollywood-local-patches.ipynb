{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Local Patches\n",
    "\n",
    "* Keep color\n",
    "* Patches of mxm pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import lmdb\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "video_files = os.listdir(\"videoclips\")\n",
    "annotation_files = os.listdir(\"annotations\")\n",
    "\n",
    "video_files.remove(\"example.avi\")\n",
    "\n",
    "def log(string):\n",
    "    print \"%s: %s\" % (str(datetime.datetime.now())[:-7], string)\n",
    "    \n",
    "proportion = 1.0\n",
    "\n",
    "with open(\"annotations/train_clean.txt\") as fp:\n",
    "    train_clean = fp.readlines()\n",
    "    train_clean = [f[:-2] for f in train_clean]\n",
    "    print len(train_clean)\n",
    "    train_clean = np.random.choice(train_clean, int(len(train_clean) * proportion))\n",
    "\n",
    "with open(\"annotations/test_clean.txt\") as fp:\n",
    "    test_clean = fp.readlines()\n",
    "    test_clean = [f[:-2] for f in test_clean]\n",
    "    test_clean = np.random.choice(test_clean, int(len(test_clean) * proportion))\n",
    "    \n",
    "with open(\"annotations/train_auto.txt\") as fp:\n",
    "    train_auto = fp.readlines()\n",
    "    train_auto = [f[:-2] for f in train_auto]\n",
    "    train_auto = np.random.choice(train_auto, int(len(train_auto) * proportion))\n",
    "\n",
    "height = width = 100\n",
    "    \n",
    "def get_local_patches(fname, resize=(100, 100), patch_size=(50, 50), stride=1, trim=None, show=False):\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    patches = []\n",
    "    \n",
    "    num = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = frame / 255.\n",
    "        dim = resize\n",
    "        # perform the actual resizing of the image and show it\n",
    "        frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "        # Greyscaling\n",
    "        frame = np.mean(frame, axis=2)\n",
    "        \n",
    "        for height_idx in range(0, frame.shape[0] - patch_size[0] - 1, stride):\n",
    "            for width_idx in range(0, frame.shape[1] - patch_size[1] - 1, stride):\n",
    "                num += 1\n",
    "                patch = frame[height_idx:height_idx + patch_size[0], width_idx:width_idx + patch_size[1]]\n",
    "                if len(patch.shape) == 2:\n",
    "                    patch = patch[:,:,np.newaxis]\n",
    "                if np.mean(patch) >= 0.1 and patch.var() > 0.01:\n",
    "                    patches.append(patch)\n",
    "        \n",
    "#         for height_batch_i in range(frame.shape[0] // patch_size[0]):\n",
    "#             for width_batch_i in range(frame.shape[1] // patch_size[1]):\n",
    "#                 patch = frame[height_batch_i * patch_size[0]:(height_batch_i + 1) * patch_size[0],\n",
    "#                              width_batch_i * patch_size[1]:(width_batch_i + 1) * patch_size[1],:]\n",
    "#                 if np.mean(patch) >= 0.1: # Avoid very dark images\n",
    "#                     patches.append(patch)\n",
    "\n",
    "    log(\"Number of patches: %i\" % len(patches))\n",
    "\n",
    "    if show:\n",
    "        f1 = patches[random.sample(range(len(patches)),1)[0]]\n",
    "        cv_rgb = f1\n",
    "        log(\"Shape: %s\" % str(cv_rgb.shape))\n",
    "        log(\"Mean of this image is %.2f\" % np.mean(f1))\n",
    "        log(\"Variance of this image is %.2f\" % f1.var())\n",
    "        plt.imshow(np.mean(cv_rgb, axis=2), cmap=\"Greys_r\")\n",
    "        plt.show()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if trim is not None and len(patches) > trim:\n",
    "        orig = len(patches)\n",
    "        # Trim should < 0.5\n",
    "#         trim = int(len(patches) * trim)\n",
    "#         patches = patches[trim:-trim]\n",
    "        trim_idx = np.random.choice(range(len(patches)), trim)\n",
    "        temp = [patches[idx] for idx in trim_idx]\n",
    "        patches = temp\n",
    "        log(\"Trimmed from %i to %i patches\" % (num, len(patches)))\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video = train_clean[0].split(\"\\\"\")[1]\n",
    "patches = get_local_patches(\"videoclips/\" + video, patch_size=(80, 80), trim=1000, resize=(200, 200),\n",
    "                            stride = 20, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trim = 1000\n",
    "resize = (200, 200)\n",
    "patch_size = (80, 80)\n",
    "stride = 20\n",
    "\n",
    "all_patches = []\n",
    "\n",
    "log(\"%i files in total\" % len(train_clean))\n",
    "\n",
    "for idx, f in enumerate(train_clean):\n",
    "    video = f.split(\"\\\"\")[1]\n",
    "    patches = get_local_patches(\"videoclips/\" + video, \n",
    "                    patch_size=patch_size, resize=resize, stride=stride, trim=trim)\n",
    "#     if len(patches[0].shape) == 2:\n",
    "#         # Convert to 3-d data\n",
    "#         patches = np.array([patch[:,:,np.newaxis] for patch in patches])\n",
    "    \n",
    "    log(\"Video %i, added %i patches\" % (idx, len(patches)))\n",
    "    \n",
    "    all_patches = all_patches + patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_patches = np.array(all_patches)\n",
    "# print all_patches.shape\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, _, _ = train_test_split(all_patches, \n",
    "                                [0 for i in range(len(all_patches))], test_size=0.6)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(X_train[0], axis=2), cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "height, width = patch_size\n",
    "\n",
    "def autoencoder(input_shape=[None, height, width, 1],\n",
    "                n_filters=[1, 3, 3, 3, 3, 3],\n",
    "                filter_sizes=[3, 3, 3, 3, 3],\n",
    "                corruption=False):\n",
    "    # %%\n",
    "    # input to the network\n",
    "    x = tf.placeholder(tf.float32, input_shape, name='x')\n",
    "\n",
    "\n",
    "    # %%\n",
    "    # ensure 2-d is converted to square tensor.\n",
    "    if len(x.get_shape()) == 2:\n",
    "        x_dim = np.sqrt(x.get_shape().as_list()[1])\n",
    "        if x_dim != int(x_dim):\n",
    "            raise ValueError('Unsupported input dimensions')\n",
    "        x_dim = int(x_dim)\n",
    "        x_tensor = tf.reshape(\n",
    "            x, [-1, x_dim, x_dim, n_filters[0]])\n",
    "    elif len(x.get_shape()) == 4:\n",
    "        x_tensor = x\n",
    "    else:\n",
    "        raise ValueError('Unsupported input dimensions')\n",
    "    current_input = x_tensor\n",
    "\n",
    "    # %%\n",
    "    # Build the encoder\n",
    "    encoder_weights = []\n",
    "    encoder_ops = []\n",
    "    shapes = []\n",
    "    for layer_i, n_output in enumerate(n_filters[1:]):\n",
    "        n_input = current_input.get_shape().as_list()[3]\n",
    "        shapes.append(current_input.get_shape().as_list())\n",
    "        W = tf.Variable(\n",
    "            tf.random_uniform([\n",
    "                filter_sizes[layer_i],\n",
    "                filter_sizes[layer_i],\n",
    "                n_input, n_output],\n",
    "                -1.0 / math.sqrt(n_input),\n",
    "                1.0 / math.sqrt(n_input)))\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        encoder_weights.append(W)\n",
    "        output = tf.nn.sigmoid(\n",
    "            tf.add(tf.nn.conv2d(\n",
    "                current_input, W, strides=[1, 1, 1, 1], padding='SAME'), b))\n",
    "        encoder_ops.append(output)\n",
    "        current_input = output\n",
    "\n",
    "    # %%\n",
    "    # store the latent representation\n",
    "    z = current_input\n",
    "    encoder_weights.reverse()\n",
    "    shapes.reverse()\n",
    "\n",
    "    # %%\n",
    "    # Build the decoder using the same weights\n",
    "    for layer_i, shape in enumerate(shapes):\n",
    "        W = encoder_weights[layer_i]\n",
    "        b = tf.Variable(tf.zeros([W.get_shape().as_list()[2]]))\n",
    "        output = tf.nn.sigmoid(\n",
    "            tf.add(tf.nn.conv2d_transpose(\n",
    "                current_input, W,\n",
    "                tf.pack([tf.shape(x)[0], shape[1], shape[2], shape[3]]),\n",
    "                strides=[1, 1, 1, 1], padding='SAME'), b))\n",
    "        current_input = output\n",
    "        \n",
    "    decoder = current_input\n",
    "\n",
    "    # %%\n",
    "    # now have the reconstruction through the network\n",
    "    y = current_input\n",
    "    # cost function measures pixel-wise difference\n",
    "    cost = tf.reduce_sum(tf.square(y - x_tensor))\n",
    "\n",
    "    # %%\n",
    "    return {'x': x, 'z': z, 'y': y, 'cost': cost, \n",
    "            \"encoder\": encoder_ops, \"decoder\": decoder}\n",
    "\n",
    "\n",
    "# %%\n",
    "def test_hollywood(X_train, X_test, n_filters, filter_sizes):\n",
    "    import tensorflow as tf\n",
    "    ae = autoencoder(n_filters=n_filters, filter_sizes=filter_sizes)\n",
    "\n",
    "    # %%\n",
    "    learning_rate = 0.001\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(ae['cost'])\n",
    "\n",
    "    # %%\n",
    "    # We create a session to use the graph\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    sess = tf.Session(config=config)\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # %%\n",
    "    # Fit all training data\n",
    "    batch_size = 100\n",
    "    n_epochs = 50\n",
    "    step_size = 10\n",
    "    for epoch_i in range(n_epochs):\n",
    "        for batch_i in range(X_train.shape[0] // batch_size):\n",
    "            batch_xs = X_train[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "            train = batch_xs\n",
    "            sess.run(optimizer, feed_dict={ae['x']: train})\n",
    "        if epoch_i % step_size == 0:\n",
    "            print(str(datetime.datetime.now()), epoch_i, sess.run(ae['cost'], feed_dict={ae['x']: train}))\n",
    "\n",
    "#     # %%\n",
    "#     # Plot example reconstructions\n",
    "#     n_examples = 5\n",
    "#     test_xs = np.array(X_test[:n_examples])\n",
    "#     test_xs_norm = test_xs\n",
    "#     recon = sess.run(ae['y'], feed_dict={ae['x']: test_xs_norm})\n",
    "#     print test_xs.shape\n",
    "#     print(recon.shape)\n",
    "#     fig, axs = plt.subplots(2, n_examples, figsize=(30, 15))\n",
    "#     for example_i in range(n_examples):\n",
    "#         axs[0][example_i].imshow(\n",
    "#             test_xs[example_i, :].reshape((height, width, 3))[:,:,::-1])\n",
    "#         axs[0][example_i].axis(\"off\")\n",
    "\n",
    "#         axs[1][example_i].imshow(\n",
    "#             recon[example_i, ...].reshape((height, width, 3))[:,:,::-1])\n",
    "# #                 np.reshape(recon[example_i, ...], (height, width, 3)))\n",
    "#         axs[1][example_i].axis(\"off\")\n",
    "    \n",
    "#     fig.show()\n",
    "#     plt.draw()\n",
    "    \n",
    "    ae[\"session\"] = sess\n",
    "    \n",
    "    return ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae = test_hollywood(X_train, X_test, n_filters=[3, 5, 5, 5, 5],\n",
    "                filter_sizes=[3, 3, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del ae, sess, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = X_train[:40000]\n",
    "combined = []\n",
    "sess = ae[\"session\"]\n",
    "batch_size = 100\n",
    "for batch_i in range(train.shape[0] // batch_size):\n",
    "    batch_xs = train[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "    layers = [sess.run(ae[\"encoder\"][i], \n",
    "            feed_dict={ae['x']: batch_xs}) for i in range(len(ae[\"encoder\"]))]\n",
    "    ravels = (np.array([row.ravel() for row in layers[i]]) for i in range(len(ae[\"encoder\"])))\n",
    "    interm = np.hstack((ravels))\n",
    "    combined.append(interm)\n",
    "    \n",
    "combined = np.vstack((combined))\n",
    "print combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "import random\n",
    "\n",
    "test_idxes = random.sample(range(combined.shape[0]), 10)\n",
    "# test_idxes = random.sample(np.where(y_train == 0)[0], 10)\n",
    "print test_idxes\n",
    "\n",
    "tree = cKDTree(combined)\n",
    "test_array = combined[test_idxes]\n",
    "query_res = tree.query(test_array, k=20)\n",
    "\n",
    "nns = []\n",
    "\n",
    "for idx, row in enumerate(query_res[1]):\n",
    "    nn = train[row.ravel()]\n",
    "#     to_plot = np.vstack([X_test[idx], nn])\n",
    "    nns.append(nn)\n",
    "    \n",
    "nns = np.stack(nns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_nearest_neighbors(nns, reshape=(height, width, 3), cols=5, reverse=False):\n",
    "    fig, axs = plt.subplots(nns.shape[0], cols, figsize=(32, 32))\n",
    "    \n",
    "    for i in range(nns.shape[0]):\n",
    "        for j in range(cols):\n",
    "            neighbor_index = -1 * j if reverse else j\n",
    "            if len(reshape) != 2:\n",
    "                axs[i][j].imshow(np.mean(nns[i, neighbor_index], axis=2), cmap=\"Greys_r\")\n",
    "            else:\n",
    "                axs[i][j].imshow(\n",
    "                    nns[i, neighbor_index][:,:,0].reshape(reshape), cmap=\"Greys_r\")\n",
    "            axs[i][j].axis(\"off\")\n",
    "    fig.subplots_adjust(wspace=0, hspace=0)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_nearest_neighbors(nns, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
