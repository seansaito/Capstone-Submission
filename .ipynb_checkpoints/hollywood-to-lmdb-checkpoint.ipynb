{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import lmdb\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "video_files = os.listdir(\"videoclips\")\n",
    "annotation_files = os.listdir(\"annotations\")\n",
    "\n",
    "video_files.remove(\"example.avi\")\n",
    "\n",
    "def log(string):\n",
    "    print \"%s: %s\" % (str(datetime.datetime.now())[:-6], string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proportion = 0.3\n",
    "\n",
    "with open(\"annotations/train_clean.txt\") as fp:\n",
    "    train_clean = fp.readlines()\n",
    "    train_clean = [f[:-2] for f in train_clean]\n",
    "    print len(train_clean)\n",
    "    train_clean = np.random.choice(train_clean, int(len(train_clean) * proportion))\n",
    "\n",
    "with open(\"annotations/test_clean.txt\") as fp:\n",
    "    test_clean = fp.readlines()\n",
    "    test_clean = [f[:-2] for f in test_clean]\n",
    "    test_clean = np.random.choice(test_clean, int(len(test_clean) * proportion))\n",
    "    \n",
    "with open(\"annotations/train_auto.txt\") as fp:\n",
    "    train_auto = fp.readlines()\n",
    "    train_auto = [f[:-2] for f in train_auto]\n",
    "    train_auto = np.random.choice(train_auto, int(len(train_auto) * proportion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_clean[0].split(\"<\")[1].split(\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernels\n",
    "\n",
    "sobel_x = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ])\n",
    "\n",
    "sobel_y = np.array([\n",
    "        [1, 2, 1],\n",
    "        [0, 0, 0],\n",
    "        [-1, -2, -1]\n",
    "    ])\n",
    "\n",
    "kernels = {\n",
    "    \"sobel\": [sobel_x, sobel_y]\n",
    "}\n",
    "\n",
    "def convolution(X, kernel):\n",
    "    \"\"\"\n",
    "    Apply convolution over an image using a kernel\n",
    "    \n",
    "    Args:\n",
    "        X         : numpy.ndarray\n",
    "            input image\n",
    "        kernel    : list\n",
    "            list of filters. All filters should have the same dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    shape = X.shape\n",
    "    kernel_shape = kernel[0].shape\n",
    "    \n",
    "    # Number of rows and columns\n",
    "    target_x = shape[0] - kernel_shape[0] + 1\n",
    "    target_y = shape[1] - kernel_shape[1] + 1\n",
    "    \n",
    "    target = np.zeros((target_x, target_y))\n",
    "    \n",
    "    for i in range(target_x):\n",
    "        for j in range(target_y):\n",
    "            input_sub = X[i:(i+kernel_shape[0]), j:(j+kernel_shape[1])]\n",
    "            combined = 0\n",
    "            for f in kernel:\n",
    "                interm = np.sum(np.multiply(input_sub, f))\n",
    "                combined += interm\n",
    "            target[i, j] = combined\n",
    "    \n",
    "    return target\n",
    "\n",
    "def capture_and_release(fname, resize=(200, 200), sobel=False, show=False):\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "    rets, frames = [], []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        rets.append(ret)\n",
    "        if resize is not None:\n",
    "            frame = np.array(Image.fromarray(np.array(frame).astype(np.uint8)).resize(resize))\n",
    "        if sobel:\n",
    "            frame = convolution(frame, kernels[\"sobel\"])\n",
    "            frame = frame.astype(np.float32)\n",
    "        frame = frame / 255.\n",
    "        frames.append(frame)\n",
    "\n",
    "\n",
    "    if show:\n",
    "        f1 = frames[1]\n",
    "        cv_rgb = f1\n",
    "        print \"Shape: \", cv_rgb.shape\n",
    "        print \"Number of frames: \", len(frames)\n",
    "        if sobel:\n",
    "            plt.imshow(cv_rgb, cmap=\"Greys_r\")\n",
    "        else:\n",
    "            plt.imshow(cv_rgb)\n",
    "        plt.show()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"videoclips/example.avi\"\n",
    "frames = capture_and_release(fname, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary that has two levels:\n",
    "# video file name => frame number => label (can have multiple)\n",
    "video_to_frame_to_label = {fname: {} for fname in video_files}\n",
    "stores = [train_clean, test_clean, train_auto]\n",
    "\n",
    "label_bank = {\"None\": 0, \"SitUp\": 1, \"GetOutCar\": 2, \"StandUp\": 3, \"AnswerPhone\": 4,\n",
    "             \"Kiss\": 5, \"HugPerson\": 6, \"HandShake\": 7, \"SitDown\": 8}\n",
    "\n",
    "for idx, store in enumerate(stores):\n",
    "    for line in store:\n",
    "        video_title = line.split(\"\\\"\")[1]\n",
    "        begin, end = map(int, line.split(\"(\")[1].split(\")\")[0].split(\"-\"))\n",
    "        labels = []\n",
    "        label_group = line.split(\"<\")[1:]\n",
    "        for l in label_group:\n",
    "            label = l.split(\">\")[0]\n",
    "            labels.append(label_bank[label])\n",
    "        for i in range(begin - 1, end + 1):\n",
    "            if i in video_to_frame_to_label[video_title]:\n",
    "                video_to_frame_to_label[video_title][i] = \\\n",
    "                        video_to_frame_to_label[video_title][i] + labels                           \n",
    "            else:\n",
    "                video_to_frame_to_label[video_title][i] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_to_frame_to_label.keys()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Additional helper functions\n",
    "\n",
    "\n",
    "def get_frames_and_labels(f, sobel=False):\n",
    "    \"\"\"\n",
    "    Assuming that f is of the form videoclips/FILENAME.avi\n",
    "    \"\"\"\n",
    "    frames = capture_and_release(f, sobel=sobel)\n",
    "    video_title = f.split(\"/\")[1]\n",
    "    return_frames = []\n",
    "    return_labels = []\n",
    "    for idx, frame in enumerate(frames):\n",
    "        if frame is not None:\n",
    "            if idx in video_to_frame_to_label[video_title]:\n",
    "                labels = video_to_frame_to_label[video_title][idx]\n",
    "    #             print \"Labels length: \", len(labels)\n",
    "                for label in labels:\n",
    "                    return_frames.append(frame) # If a frame has two labels, we add two frames\n",
    "                    return_labels.append(label)\n",
    "    #                 print \"Return frames length: \", len(return_frames)\n",
    "    #                 print \"Return labels length: \", len(labels)\n",
    "            else:\n",
    "                return_frames.append(frame)\n",
    "                return_labels.append(0) # For non-annotated frames\n",
    "    return return_frames, return_labels\n",
    "\n",
    "# Write to the lmdb\n",
    "def write_to_lmdb(lmdb_name, frames, labels=None, write_label=True):\n",
    "    map_size = np.array(frames).nbytes * 10\n",
    "    env = lmdb.open(lmdb_name, map_size=map_size)\n",
    "    \n",
    "    with env.begin(write=True) as txn:\n",
    "        for i in range(len(frames)):\n",
    "            datum = caffe.proto.caffe_pb2.Datum()\n",
    "            datum.channels = frames[i].shape[2]\n",
    "            datum.width = frames[i].shape[1]\n",
    "            datum.height = frames[i].shape[0]\n",
    "            datum.data = np.array(frames[i]).tobytes()\n",
    "            if write_label:\n",
    "                datum.label = int(labels[i])\n",
    "            str_id = \"{:08}\".format(i)\n",
    "            \n",
    "            txn.put(str_id, datum.SerializeToString())\n",
    "\n",
    "key_store = range(200000)\n",
    "random.shuffle(key_store)\n",
    "            \n",
    "# Append to an existing LMDB\n",
    "def append_to_lmdb(lmdb_name, frames, labels=None, trim=None, write_label=True, first_time=False):\n",
    "    map_size = np.array(frames).nbytes * 1e4\n",
    "    log(\"Created\")\n",
    "    log(\"%i frames\" % len(frames))\n",
    "    env = lmdb.open(lmdb_name, map_size=map_size)\n",
    "    \n",
    "    # Get the max_key\n",
    "    max_key = 0\n",
    "    if not first_time:\n",
    "#         max_key = env.stat()[\"entries\"]\n",
    "        max_key = env.stat()[\"entries\"]\n",
    "        log(\"%i entries so far\" % max_key)\n",
    "    \n",
    "    if trim is not None:\n",
    "        # Trim should < 0.5\n",
    "        trim = int(len(frames) * trim)\n",
    "        frames = frames[trim:-trim]\n",
    "        log(\"Trimmed to %i frames\" % len(frames))\n",
    "\n",
    "    \n",
    "    with env.begin(write=True) as txn:\n",
    "        for i in range(len(frames)):\n",
    "            datum = caffe.proto.caffe_pb2.Datum()\n",
    "            datum.channels = frames[i].shape[2]\n",
    "            datum.width = frames[i].shape[1]\n",
    "            datum.height = frames[i].shape[0]\n",
    "            datum.data = np.array(frames[i]).tobytes()\n",
    "            if write_label:\n",
    "                datum.label = int(labels[i])\n",
    "            str_id = '{:08}'.format(key_store[max_key + 1 + i])\n",
    "            txn.put(str_id, datum.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_lmdb(fnames, db, trim=None, sobel=False):\n",
    "    total = len(fnames)\n",
    "    for idx, f in enumerate(fnames):\n",
    "        video = f.split(\"\\\"\")[1]\n",
    "        log(\"%i, %s\" % (idx, video))\n",
    "        frames, labels = get_frames_and_labels(\"videoclips/\" + video, sobel=sobel)\n",
    "        if len(frames[0].shape) == 2:\n",
    "            # Convert to 3-d data\n",
    "            frames = np.array([frame[:,:,np.newaxis] for frame in frames])\n",
    "        first_time = False\n",
    "        if idx == 0:\n",
    "            first_time = True\n",
    "        append_to_lmdb(db, frames[:-1], labels[:-1], trim=trim, first_time=first_time)\n",
    "        log(\"Finished %i/%i\" % (idx, total))\n",
    "        time.sleep(1)\n",
    "    log(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_lmdb(train_clean, \"train_clean_small_lmdb\", trim=0.4, sobel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_lmdb(test_clean, \"test_clean_small_lmdb\", trim=0.45, sobel=False)\n",
    "\n",
    "\n",
    "# for idx, f in enumerate(test_clean):\n",
    "#     video = f.split(\"\\\"\")[1]\n",
    "#     print \"%i, %s\" % (idx, video)\n",
    "#     frames, labels = get_frames_and_labels(\"videoclips/\" + video)\n",
    "#     first_time = False\n",
    "#     if idx == 0:\n",
    "#         first_time = True\n",
    "#     append_to_lmdb(\"test_clean_lmdb\", frames[:-1], labels[:-1], first_time)\n",
    "#     print \"Finished %i\" % idx\n",
    "#     time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total = []\n",
    "for f in train_clean:\n",
    "    video = f.split(\"\\\"\")[1]\n",
    "    frames, labels = get_frames_and_labels(\"videoclips/\" + video, sobel=False)\n",
    "    if len(frames[0].shape) == 2:\n",
    "        # Convert to 3-d data\n",
    "        frames = np.array([frame[:,:,np.newaxis] for frame in frames])\n",
    "    total = total + frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
